{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import uuid\n",
    "from pdf2image import convert_from_path\n",
    "import easyocr, pytesseract\n",
    "import cv2, numpy as np\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = Path(\"../data/0.pdf\")\n",
    "EMBED_MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "CHROMA_DIR = \"chroma_db_notebook\"\n",
    "COLLECTION_NAME = \"megher_nb\"\n",
    "TOP_K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6083852",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path(str(PDF_PATH), dpi=300)\n",
    "print(\"Pages converted:\", len(pages))\n",
    "\n",
    "# show first page\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.imshow(pages[0])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Page 1 (raw)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b422e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, max_side=2000):\n",
    "    h,w = img.shape[:2]\n",
    "    if max(h,w) <= max_side:\n",
    "        return img\n",
    "    scale = max_side / max(h,w)\n",
    "    return cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add98967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(img):\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                 cv2.THRESH_BINARY, 35, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a80af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = cv2.cvtColor(np.array(pages[0]), cv2.COLOR_RGB2BGR)\n",
    "img0 = resize_image(img0)\n",
    "b0 = binarize(img0)\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.imshow(b0, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Page 1 (binarized)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59cb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader([\"bn\",\"en\"], gpu=False)  # set gpu=True if available\n",
    "pages_text = []\n",
    "MAX_PAGES = min(10, len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1136fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(MAX_PAGES):\n",
    "    pil = pages[i]\n",
    "    img = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)\n",
    "    img = resize_image(img)\n",
    "    img_bin = binarize(img)\n",
    "    try:\n",
    "        easy_res = reader.readtext(img_bin, detail=0)\n",
    "        text_easy = \"\\n\".join(easy_res).strip()\n",
    "    except Exception:\n",
    "        text_easy = \"\"\n",
    "    if len(text_easy) < 20:\n",
    "        tesseract_txt = pytesseract.image_to_string(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), lang=\"ben+eng\")\n",
    "        text = tesseract_txt.strip() if len(tesseract_txt.strip()) > len(text_easy) else text_easy\n",
    "        engine = \"tesseract\" if text == tesseract_txt.strip() else \"easyocr\"\n",
    "    else:\n",
    "        text = text_easy\n",
    "        engine = \"easyocr\"\n",
    "    pages_text.append({\"page\": i+1, \"text\": text, \"engine\": engine})\n",
    "print(\"OCRed pages (demo):\", len(pages_text))\n",
    "print(\"Sample (page 1) snippet:\", pages_text[0][\"text\"][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    if not s:\n",
    "        return s\n",
    "    s = s.replace(\"-\\n\", \"\")\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\")\n",
    "    s = \" \".join(s.split())\n",
    "    s = s.replace(\"|\", \"।\")\n",
    "    return s.strip()\n",
    "\n",
    "for p in pages_text:\n",
    "    p[\"clean\"] = clean_text(p[\"text\"])\n",
    "\n",
    "print(\"Clean snippet (page1):\", pages_text[0][\"clean\"][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56889d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)\n",
    "documents = []\n",
    "for p in pages_text:\n",
    "    if not p[\"clean\"]:\n",
    "        continue\n",
    "    chunks = splitter.split_text(p[\"clean\"])\n",
    "    for idx, c in enumerate(chunks):\n",
    "        documents.append(Document(page_content=c, metadata={\"page\": p[\"page\"], \"chunk_id\": f\"{p['page']}_{idx}\", \"engine\": p[\"engine\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chunks created (demo):\", len(documents))\n",
    "print(\"Example metadata:\", documents[0].metadata)\n",
    "print(\"Example chunk (first 200 chars):\\n\", documents[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(EMBED_MODEL)\n",
    "N = min(200, len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [d.page_content for d in documents[:N]]\n",
    "metas = [d.metadata for d in documents[:N]]\n",
    "embs = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb246269",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "XY = pca.fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "pages_list = [m[\"page\"] for m in metas]\n",
    "sc = plt.scatter(XY[:,0], XY[:,1], c=pages_list, cmap=\"tab20\", s=30)\n",
    "plt.colorbar(sc, label=\"page\")\n",
    "plt.title(f\"PCA of chunk embeddings (first {N} chunks)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f65133",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client(Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=CHROMA_DIR))\n",
    "try:\n",
    "    coll = client.get_collection(COLLECTION_NAME)\n",
    "except Exception:\n",
    "    coll = client.create_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342abb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [m[\"chunk_id\"] for m in metas]\n",
    "docs_texts = texts\n",
    "metadatas = metas\n",
    "coll.add(ids=ids, documents=docs_texts, metadatas=metadatas, embeddings=embs.tolist())\n",
    "client.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4114ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chroma items (approx):\", len(coll.get().get(\"ids\", [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d34d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"বৃষ্টির বর্ণনা কেন গুরুত্বপূর্ণ ছিল?\"\n",
    "q_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "res = coll.query(query_embeddings=[q_emb.tolist()], n_results=TOP_K, include=[\"metadatas\",\"documents\",\"distances\"])uv sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20874368",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = []\n",
    "for i in range(len(res[\"ids\"][0])):\n",
    "    retrieved.append({\n",
    "        \"id\": res[\"ids\"][0][i],\n",
    "        \"doc\": res[\"documents\"][0][i],\n",
    "        \"meta\": res[\"metadatas\"][0][i],\n",
    "        \"distance\": res[\"distances\"][0][i]\n",
    "    })\n",
    "\n",
    "for i, r in enumerate(retrieved):\n",
    "    print(f\"Rank {i+1} | id={r['id']} | page={r['meta']['page']} | distance={r['distance']:.4f}\")\n",
    "    print(r[\"doc\"][:300].replace(\"\\n\",\" \") + \"\\n\" + \"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceeaff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embs = [model.encode([r[\"doc\"]], convert_to_numpy=True, normalize_embeddings=True)[0] for r in retrieved]\n",
    "sims = cosine_similarity([q_emb], doc_embs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da61a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "plt.bar(range(1, len(sims)+1), sims)\n",
    "plt.xticks(range(1, len(sims)+1))\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Cosine similarity\")\n",
    "plt.title(\"Query vs retrieved chunk similarity\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show table\n",
    "pd.DataFrame([{\"rank\": i+1, \"id\": r[\"id\"], \"page\": r[\"meta\"][\"page\"], \"similarity\": float(s)} for i,(r,s) in enumerate(zip(retrieved, sims))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_OLLAMA = False  # set True to use local Ollama API at http://localhost:11434\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n---\\n\\n\".join([r[\"doc\"] for r in retrieved])\n",
    "detected = detect(query)\n",
    "if detected.startswith(\"bn\"):\n",
    "    prompt = f\"রেফারেন্স:\\n{context}\\n\\nপ্রশ্ন: {query}\\n\\nসংক্ষিপ্তভাবে বাংলায় উত্তর দিন:\"\n",
    "else:\n",
    "    prompt = f\"Reference:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer briefly in English:\"\n",
    "\n",
    "if USE_OLLAMA:\n",
    "    import requests\n",
    "    resp = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": prompt, \"max_tokens\": 512}, timeout=60)\n",
    "    print(\"Ollama:\", resp.json())\n",
    "elif OPENAI_API_KEY:\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    resp = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\",\"content\":prompt}], max_tokens=512, temperature=0.2)\n",
    "    ans = resp.choices[0].message.content\n",
    "    print(\"LLM answer:\\n\", ans)\n",
    "else:\n",
    "    print(\"No LLM configured (set OPENAI_API_KEY or USE_OLLAMA=True).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i,(r,s) in enumerate(zip(retrieved, sims)):\n",
    "    rows.append({\"rank\": i+1, \"id\": r[\"id\"], \"page\": r[\"meta\"][\"page\"], \"similarity\": float(s), \"snippet\": r[\"doc\"][:400]})\n",
    "df = pd.DataFrame(rows)\n",
    "out = Path(\"../data\") / \"retrieval_eval.csv\"\n",
    "df.to_csv(out, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saved retrieval_eval.csv ->\", out)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99befb",
   "metadata": {},
   "source": [
    "## Next steps (practical)\n",
    "- If this notebook works, extract the functions into the modular files (`src/ocr_extraction.py`, `src/preprocess.py`, etc.).\n",
    "- For production ingestion, use a background worker (Celery/RQ) for large PDFs.\n",
    "- Improve OCR by tuning `binarize`/deskew or using GPU for EasyOCR.\n",
    "- Use GPU for sentence-transformers to speed up embedding large volumes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multilingual-RAG-System-for-Q-A-with-PDF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
